// src/vulnerability_matcher.rs - Optimized implementation

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::error::Error;
use std::sync::Arc;
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::sync::Mutex;
use regex::Regex;
use futures::future::join_all;
use crate::dork_engine::DorkResult;
use crate::Finding;
use url::Url; // Added for URL parsing

/// Represents a vulnerability pattern to match against content
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VulnerabilityPattern {
    pub id: String,
    pub name: String,
    pub category: String,
    pub regex_pattern: String,
    pub severity: String,  // "Critical", "High", "Medium", "Low", "Info"
    pub platforms: Vec<String>,
    pub false_positive_checks: Vec<String>,
    pub cwe_id: Option<String>,        // Common Weakness Enumeration ID
    pub remediation: Option<String>,   // Suggested fix
}

/// Configuration for context extraction
#[derive(Debug, Clone)]
struct ContextConfig {
    before_chars: usize,  // Characters to include before match
    after_chars: usize,   // Characters to include after match
    highlight_match: bool, // Whether to highlight the matched portion
}

/// Represents a match between content and a vulnerability pattern
#[derive(Debug, Clone)] // Derive Clone for easier use in collection
pub struct VulnerabilityMatch {
    pub pattern_id: String,
    pub pattern_name: String,
    pub url: String,
    pub matched_content: String,
    pub context: String,
    pub severity: String,
    pub cwe_id: Option<String>,
    pub remediation: Option<Option<String>>, // Changed to Option<Option<String>> to align with Finding's remediation structure if needed later
}

/// Main vulnerability matcher for detecting security issues
pub struct VulnerabilityMatcher {
    patterns: Vec<VulnerabilityPattern>,
    compiled_regexes: HashMap<String, Regex>,
    context_config: ContextConfig,
    common_false_positives: Vec<String>,
}

impl VulnerabilityMatcher {
    /// Create a new VulnerabilityMatcher with default patterns
    pub fn new() -> Self {
        // Define default vulnerability patterns
        let patterns = vec![
            // SQL Injection patterns
            VulnerabilityPattern {
                id: "SQLI-01".to_string(),
                name: "SQL Syntax Error Disclosure".to_string(),
                category: "SQL Injection".to_string(),
                regex_pattern: r"(?i)(sql syntax|sql error|ORA-\d{5}|mysql_fetch_array\(\)|syntax error has occurred|Microsoft OLE DB Provider for SQL Server)".to_string(),
                severity: "High".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![
                    "documentation".to_string(),
                    "example".to_string(),
                ],
                cwe_id: Some("CWE-89".to_string()),
                remediation: Some("Implement parameterized queries or prepared statements to prevent SQL injection.".to_string()),
            },

            // XSS patterns
            VulnerabilityPattern {
                id: "XSS-01".to_string(),
                name: "Reflected XSS Vulnerability".to_string(),
                category: "Cross-Site Scripting".to_string(),
                regex_pattern: r"(?i)(alert\s*\(|confirm\s*\(|prompt\s*\(|<script>|javascript:)".to_string(),
                severity: "Medium".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![
                    "documentation".to_string(),
                    "example".to_string(),
                ],
                cwe_id: Some("CWE-79".to_string()),
                remediation: Some("Sanitize and validate all user input. Implement Content-Security-Policy headers and use frameworks that automatically escape output.".to_string()),
            },

            // Sensitive data exposure
            VulnerabilityPattern {
                id: "EXPOSURE-01".to_string(),
                name: "API Key Exposure".to_string(),
                category: "Sensitive Data Exposure".to_string(),
                regex_pattern: r"(?i)(api_key|apikey|api-key|access_token|secret_key|password)\s*[:=]\s*['\"]([\w\-\.]{10,})['\"]\s*".to_string(),
                severity: "Critical".to_string(),
                platforms: vec!["Web".to_string(), "Mobile".to_string()],
                false_positive_checks: vec![
                    "placeholder".to_string(),
                    "example".to_string(),
                    "YOUR_API_KEY".to_string(),
                ],
                cwe_id: Some("CWE-312".to_string()),
                remediation: Some("Never store sensitive credentials in client-side code. Use environment variables or secure credential storage.".to_string()),
            },

            // Open redirect
            VulnerabilityPattern {
                id: "REDIRECT-01".to_string(),
                name: "Open Redirect Vulnerability".to_string(),
                category: "Open Redirect".to_string(),
                regex_pattern: r"(?i)(redirect|redir|url|link|goto|return_to)\s*=\s*(https?:\/\/|\/\/|\.\.\/|\/)".to_string(),
                severity: "Medium".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![],
                cwe_id: Some("CWE-601".to_string()),
                remediation: Some("Implement a whitelist of allowed redirect destinations and validate all redirect URLs against this list.".to_string()),
            },

            // Admin interfaces
            VulnerabilityPattern {
                id: "ADMIN-01".to_string(),
                name: "Exposed Admin Interface".to_string(),
                category: "Information Disclosure".to_string(),
                regex_pattern: r"(?i)(admin|administrator|administration|login|backend|cpanel|wp-admin)".to_string(),
                severity: "Medium".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![],
                cwe_id: Some("CWE-200".to_string()),
                remediation: Some("Restrict access to administrative interfaces with proper authentication and IP restrictions.".to_string()),
            },

            // Error disclosure
            VulnerabilityPattern {
                id: "ERROR-01".to_string(),
                name: "Detailed Error Messages".to_string(),
                category: "Information Disclosure".to_string(),
                regex_pattern: r"(?i)(exception|stack trace|debug info|error in|undefined index|fatal error)".to_string(),
                severity: "Low".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![
                    "documentation".to_string(),
                ],
                cwe_id: Some("CWE-209".to_string()),
                remediation: Some("Configure proper error handling to display generic error messages to users while logging detailed errors for administrators.".to_string()),
            },

            // CORS misconfiguration
            VulnerabilityPattern {
                id: "CORS-01".to_string(),
                name: "CORS Misconfiguration".to_string(),
                category: "Security Misconfiguration".to_string(),
                regex_pattern: r"(?i)(Access-Control-Allow-Origin:\s*\*)".to_string(),
                severity: "Medium".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![],
                cwe_id: Some("CWE-942".to_string()),
                remediation: Some("Configure CORS headers with specific origins instead of using wildcards.".to_string()),
            },

            // JWT exposure
            VulnerabilityPattern {
                id: "JWT-01".to_string(),
                name: "JWT Token Exposure".to_string(),
                category: "Sensitive Data Exposure".to_string(),
                regex_pattern: r"eyJ[a-zA-Z0-9_-]{5,}\.eyJ[a-zA-Z0-9_-]{5,}\.[a-zA-Z0-9_-]{5,}".to_string(),
                severity: "High".to_string(),
                platforms: vec!["Web".to_string()],
                false_positive_checks: vec![
                    "example".to_string(),
                ],
                cwe_id: Some("CWE-522".to_string()),
                remediation: Some("Do not expose JWTs in client-side code or URLs. Store tokens securely using httpOnly cookies.".to_string()),
            },
        ];

        // Compile regexes
        let mut compiled_regexes = HashMap::new();
        for pattern in &patterns {
            match Regex::new(&pattern.regex_pattern) {
                Ok(regex) => {
                    compiled_regexes.insert(pattern.id.clone(), regex);
                },
                Err(e) => {
                    eprintln!("Failed to compile regex pattern for {}: {}", pattern.id, e);
                }
            }
        }

        // Default context configuration
        let context_config = ContextConfig {
            before_chars: 50,
            after_chars: 50,
            highlight_match: true,
        };

        // Common false positive strings
        let common_false_positives = vec![
            "documentation".to_string(),
            "example".to_string(),
            "tutorial".to_string(),
            "sample".to_string(),
            "test".to_string(),
            "placeholder".to_string(),
        ];

        VulnerabilityMatcher {
            patterns,
            compiled_regexes,
            context_config,
            common_false_positives,
        }
    }

    /// Analyze content for vulnerabilities with improved context extraction
    pub fn analyze_content(&self, url: &str, content: &str) -> Vec<VulnerabilityMatch> {
        let mut matches = Vec::new();

        for pattern in &self.patterns {
            if let Some(regex) = self.compiled_regexes.get(&pattern.id) {
                for cap in regex.captures_iter(content) {
                    if let Some(matched) = cap.get(0) {
                        // Extract context around the match
                        let context = self.extract_context(content, matched.start(), matched.end());

                        // Check for false positives
                        if !self.is_false_positive(&pattern.false_positive_checks, &context, pattern, url) {
                            matches.push(VulnerabilityMatch {
                                pattern_id: pattern.id.clone(),
                                pattern_name: pattern.name.clone(),
                                url: url.to_string(),
                                matched_content: matched.as_str().to_string(),
                                context,
                                severity: pattern.severity.clone(),
                                cwe_id: pattern.cwe_id.clone(),
                                remediation: pattern.remediation.clone().map(Some), // Map Option<String> to Option<Option<String>>
                            });
                        }
                    }
                }
            }
        }

        matches
    }

    /// Extract context around a match with smarter boundary detection
    fn extract_context(&self, content: &str, match_start: usize, match_end: usize) -> String {
        // Determine context boundaries with sentence awareness
        let content_len = content.len();
        let before_limit = self.context_config.before_chars;
        let after_limit = self.context_config.after_chars;

        // Calculate potential start and end indices based on limits
        let raw_context_start = match_start.saturating_sub(before_limit);
        let raw_context_end = (match_end + after_limit).min(content_len);

        // Try to find a sentence or line break before the match within the limit
        let context_start = content[raw_context_start..match_start]
            .rfind(|c| c == '.' || c == '!' || c == '?' || c == '\n')
            .map_or(raw_context_start, |pos| raw_context_start + pos + 1);

        // Try to find a sentence or line break after the match within the limit
        let context_end = content[match_end..raw_context_end]
            .find(|c| c == '.' || c == '!' || c == '?' || c == '\n')
            .map_or(raw_context_end, |pos| match_end + pos + 1);

        // Ensure start is not after end and within bounds
        let final_context_start = context_start.min(match_start).max(0);
        let final_context_end = context_end.max(match_end).min(content_len);


        // Extract the context
        let mut context = content[final_context_start..final_context_end].to_string();

        // Optionally highlight the match
        if self.context_config.highlight_match {
            // Calculate relative start and end within the extracted context string
            let relative_start = match_start.saturating_sub(final_context_start);
            let relative_end = match_end.saturating_sub(final_context_start);

            // Only highlight if the indices are valid for the extracted context
            if relative_start < context.len() && relative_end <= context.len() {
                let before = &context[..relative_start];
                let matched = &context[relative_start..relative_end];
                let after = &context[relative_end..];
                context = format!("{}[MATCH: {}]{}", before, matched, after);
            }
        }

        context
    }

    /// Check if a match is a false positive
    fn is_false_positive(&self, pattern_checks: &[String], context: &str, pattern: &VulnerabilityPattern, url: &str) -> bool {
        // Check pattern-specific false positive indicators
        let lower_context = context.to_lowercase();

        for check in pattern_checks {
            if lower_context.contains(&check.to_lowercase()) {
                return true;
            }
        }

        // Check common false positives
        for check in &self.common_false_positives {
            if lower_context.contains(&check.to_lowercase()) {
                // For critical findings, be more strict about false positives
                if pattern.severity != "Critical" {
                    return true;
                }
            }
        }

        // Special case for API keys - check for common placeholders
        if pattern.id.starts_with("EXPOSURE") {
            let api_key_placeholders = [
                "your_api_key", "apikey_here", "insert_api_key",
                "xxxxxxxxxxxxxxxx", "0000000000000000", "api_key_value",
            ];

            for placeholder in &api_key_placeholders {
                if lower_context.contains(placeholder) {
                    return true;
                }
            }
        }

        // Check URL for indications of documentation or test sites
        let lower_url = url.to_lowercase();

        if lower_url.contains("docs") ||
           lower_url.contains("documentation") ||
           lower_url.contains("example") ||
           lower_url.contains("test") ||
           lower_url.contains("sample") ||
           lower_url.contains("github.com") || // Added GitHub as common place for code examples
           lower_url.contains("gitlab.com") || // Added GitLab
           lower_url.contains("bitbucket.org") // Added Bitbucket
            {
            return true;
        }

        false
    }

    /// Update vulnerability patterns from GitHub
    pub async fn update_patterns_from_github(&mut self) -> Result<(), Box<dyn Error>> {
        println!("Updating vulnerability patterns from GitHub...");

        // In a real implementation, this would fetch patterns from a GitHub repository
        // For now, we simulate a delay
        tokio::time::sleep(Duration::from_millis(500)).await;

        println!("Vulnerability patterns updated successfully");

        Ok(())
    }

    /// Analyze findings from various sources with parallel processing
    pub async fn analyze_findings(
        &self,
        target: &str,
        dork_results: &[DorkResult],
        shodan_results: &[serde_json::Value],
        urlscan_results: &[serde_json::Value],
        dns_information: &[serde_json::Value],
        js_analysis: &[serde_json::Value],
        cloud_storage: &[serde_json::Value],
    ) -> Result<Vec<Finding>, Box<dyn Error>> {
        println!("Analyzing findings from multiple sources...");

        // Create a thread-safe collection for findings
        let findings = Arc::new(Mutex::new(Vec::new()));
        let matcher = Arc::new(self); // Wrap self in Arc for sharing

        // Process different data sources in parallel
        let mut tasks = Vec::new();

        // Process dork results by analyzing snippet content
        tasks.push(tokio::spawn({
            let findings = Arc::clone(&findings);
            let matcher = Arc::clone(&matcher);
            let target = target.to_string();
            let dork_results: Vec<DorkResult> = dork_results.to_vec(); // Clone for the task
            async move {
                for result in dork_results {
                    let matches = matcher.analyze_content(&result.url, &result.snippet);
                    for m in matches {
                        let mut findings_lock = findings.lock().await;
                         findings_lock.push(Finding {
                            id: format!("FINDING-DORK-SNIPPET-{}-{}", m.pattern_id, findings_lock.len()), // Unique ID
                            target_id: target.clone(),
                            subdomain_id: extract_domain(&result.url).filter(|d| d != &target).map(|d| d.to_string()), // Extract subdomain
                            finding_type: m.pattern_name.clone(),
                            severity: m.severity.clone(),
                            url: Some(m.url.clone()),
                            description: format!("{} Matched pattern '{}' in search result snippet. Matched content: '{}'\nContext: {}", m.pattern_name, m.pattern_id, m.matched_content, m.context),
                            discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                            dork_used: Some(result.found_dork.clone()),
                            screenshot_path: None,
                            has_sensitive_data: m.severity == "Critical" || m.severity == "High", // Assume sensitive if severity is high/critical
                         });
                    }
                     // Also check URL for simple patterns like exposed admin
                     if result.url.contains("admin") ||
                        result.url.contains("login") ||
                        result.url.contains("dashboard") ||
                        result.url.contains("wp-admin") {
                         let mut findings_lock = findings.lock().await;
                          findings_lock.push(Finding {
                             id: format!("FINDING-DORK-URL-ADMIN-{}", findings_lock.len()),
                             target_id: target.clone(),
                             subdomain_id: extract_domain(&result.url).filter(|d| d != &target).map(|d| d.to_string()),
                             finding_type: "Exposed Admin Interface URL".to_string(),
                             severity: "Medium".to_string(),
                             url: Some(result.url.clone()),
                             description: format!(
                                 "Potential administrative interface URL found in search results: {}. Admin interfaces should be properly secured and not easily discoverable through search engines.",
                                 result.url
                             ),
                             discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                             dork_used: Some(result.found_dork.clone()),
                             screenshot_path: None,
                             has_sensitive_data: false,
                          });
                     }
                }
            }
        }));


        // Process JavaScript analysis findings
        tasks.push(tokio::spawn({
            let findings = Arc::clone(&findings);
            let target = target.to_string();
            let js_analysis: Vec<serde_json::Value> = js_analysis.to_vec(); // Clone for the task
            async move {
                for js_result in js_analysis {
                    // Check for API keys
                    if let Some(api_keys) = js_result.get("api_keys").and_then(|k| k.as_array()) {
                        if !api_keys.is_empty() {
                            let mut findings_lock = findings.lock().await;
                            findings_lock.push(Finding {
                                id: format!("FINDING-JS-API-KEYS-{}", findings_lock.len()), // Unique ID
                                target_id: target.clone(),
                                subdomain_id: None, // Need to extract subdomain from JS URL if available
                                finding_type: "API Key Exposure".to_string(),
                                severity: "High".to_string(),
                                url: js_result.get("url").and_then(|u| u.as_str()).map(|s| s.to_string()),
                                description: format!(
                                    "API keys found in JavaScript file that could be used to access protected APIs. This could lead to unauthorized access, data exposure, or potential service abuse: {:?}\n\nRecommendation: Never store sensitive credentials in client-side code. Use environment variables or secure credential storage.",
                                    api_keys
                                ),
                                discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                dork_used: None,
                                screenshot_path: None,
                                has_sensitive_data: true,
                            });
                        }
                    }

                    // Check for hard-coded credentials
                    if let Some(true) = js_result.get("has_credentials").and_then(|c| c.as_bool()) {
                         let mut findings_lock = findings.lock().await;
                         findings_lock.push(Finding {
                             id: format!("FINDING-JS-HARDCODED-CREDENTIALS-{}", findings_lock.len()), // Unique ID
                             target_id: target.clone(),
                             subdomain_id: None, // Need to extract subdomain from JS URL if available
                             finding_type: "Hard-coded Credentials".to_string(),
                             severity: "Critical".to_string(),
                             url: js_result.get("url").and_then(|u| u.as_str()).map(|s| s.to_string()),
                             description: "Hard-coded credentials found in JavaScript code. These credentials can be extracted and used to gain unauthorized access to systems.\n\nRecommendation: Remove all hard-coded credentials from client-side code and use secure authentication mechanisms.".to_string(),
                             discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                             dork_used: None,
                             screenshot_path: None,
                             has_sensitive_data: true,
                         });
                    }
                     // Note: Endpoints are collected separately in main.rs, not added as Findings here.
                }
            }
        }));

        // Process Shodan results
        tasks.push(tokio::spawn({
            let findings = Arc::clone(&findings);
            let target = target.to_string();
            let shodan_results: Vec<serde_json::Value> = shodan_results.to_vec(); // Clone for the task
            async move {
                for shodan_result in shodan_results {
                    // Check for vulnerabilities
                    if let Some(vulns) = shodan_result.get("vulns").and_then(|v| v.as_object()) {
                        if !vulns.is_empty() {
                            let mut findings_lock = findings.lock().await;
                            findings_lock.push(Finding {
                                id: format!("FINDING-SHODAN-VULNS-{}", findings_lock.len()), // Unique ID
                                target_id: target.clone(),
                                subdomain_id: None, // Shodan results are usually for IPs, not subdomains
                                finding_type: "Known Vulnerabilities (Shodan)".to_string(),
                                severity: "High".to_string(), // Shodan vulns are often high severity
                                url: shodan_result.get("ip_str").and_then(|ip| ip.as_str()).map(|ip| format!("http://{}", ip)),
                                description: format!(
                                    "Known vulnerabilities detected by Shodan that could be exploited. Update or patch affected systems immediately: {:?}",
                                    vulns.keys().collect::<Vec<_>>()
                                ),
                                discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                dork_used: None,
                                screenshot_path: None,
                                has_sensitive_data: false, // Varies by vulnerability
                            });
                        }
                    }

                    // Check for unusual open ports
                    if let Some(ports) = shodan_result.get("ports").and_then(|p| p.as_array()) {
                         let unusual_ports: Vec<_> = ports.iter().filter_map(|p| {
                             if let Some(port_num) = p.as_u64() {
                                match port_num {
                                     22 | 80 | 443 | 8080 | 8443 => None, // Common ports to ignore
                                     _ => Some(port_num), // Unusual port
                                }
                             } else {
                                 None
                             }
                         }).collect();


                        if !unusual_ports.is_empty() {
                            let mut findings_lock = findings.lock().await;
                            findings_lock.push(Finding {
                                id: format!("FINDING-SHODAN-UNUSUAL-PORTS-{}", findings_lock.len()), // Unique ID
                                target_id: target.clone(),
                                subdomain_id: None,
                                finding_type: "Unusual Open Ports (Shodan)".to_string(),
                                severity: "Medium".to_string(),
                                url: shodan_result.get("ip_str").and_then(|ip| ip.as_str()).map(|ip| format!("http://{}", ip)),
                                description: format!(
                                    "Unusual open ports detected by Shodan that could expose vulnerable services or provide unauthorized access paths. Consider restricting access to necessary ports only: {:?}",
                                    unusual_ports
                                ),
                                discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                dork_used: None,
                                screenshot_path: None,
                                has_sensitive_data: false,
                            });
                        }
                     // Note: More detailed Shodan data (banners, etc.) could be analyzed for more findings.
                }
            }
        }));

        // Process URLScan results
        tasks.push(tokio::spawn({
            let findings = Arc::clone(&findings);
            let target = target.to_string();
            let urlscan_results: Vec<serde_json::Value> = urlscan_results.to_vec(); // Clone for the task
            async move {
                for urlscan_result in urlscan_results {
                    if let Some(page) = urlscan_result.get("page") {
                        // Check for missing security headers
                        let missing_security_headers = vec![
                           "Content-Security-Policy",
                           "X-XSS-Protection",
                           "X-Content-Type-Options",
                           "X-Frame-Options",
                           "Strict-Transport-Security",
                           "Referrer-Policy",
                           "Permissions-Policy",
                        ];

                        let mut missing_headers = Vec::new();
                         if let Some(headers) = page.get("headers").and_then(|h| h.as_object()) {
                            for header in &missing_security_headers {
                                // Check if the header is present (case-insensitive)
                                if !headers.keys().any(|k| k.eq_ignore_ascii_case(header)) {
                                    missing_headers.push(header.to_string());
                                }
                            }
                         }


                        if !missing_headers.is_empty() {
                            let mut findings_lock = findings.lock().await;
                            findings_lock.push(Finding {
                                id: format!("FINDING-URLSCAN-MISSING-HEADERS-{}", findings_lock.len()), // Unique ID
                                target_id: target.clone(),
                                subdomain_id: page.get("domain").and_then(|d| d.as_str()).filter(|d| d != &target).map(|d| d.to_string()),
                                finding_type: "Missing Security Headers".to_string(),
                                severity: "Low".to_string(),
                                url: page.get("url").and_then(|u| u.as_str()).map(|s| s.to_string()),
                                description: format!(
                                    "Security headers are missing that could help protect against common web vulnerabilities like XSS, clickjacking, and MIME sniffing: {:?}. Implementing these headers adds important defense-in-depth protections.",
                                    missing_headers
                                ),
                                discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                dork_used: None,
                                screenshot_path: page.get("screenshot").and_then(|s| s.as_str()).map(|s| s.to_string()), // URLScan provides screenshot path
                                has_sensitive_data: false,
                            });
                        }

                        // Check for insecure content (mixed content)
                        if let Some(true) = page.get("hasInsecureContent").and_then(|v| v.as_bool()) {
                            let mut findings_lock = findings.lock().await;
                            findings_lock.push(Finding {
                                id: format!("FINDING-URLSCAN-MIXED-CONTENT-{}", findings_lock.len()), // Unique ID
                                target_id: target.clone(),
                                subdomain_id: page.get("domain").and_then(|d| d.as_str()).filter(|d| d != &target).map(|d| d.to_string()),
                                finding_type: "Mixed Content".to_string(),
                                severity: "Medium".to_string(),
                                url: page.get("url").and_then(|u| u.as_str()).map(|s| s.to_string()),
                                description: "The page loads resources over insecure HTTP connections, which can lead to man-in-the-middle attacks. All resources should be loaded over HTTPS.".to_string(),
                                discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                dork_used: None,
                                screenshot_path: page.get("screenshot").and_then(|s| s.as_str()).map(|s| s.to_string()), // URLScan provides screenshot path
                                has_sensitive_data: false,
                            });
                        }
                         // Note: URLScan provides a lot more data that could be analyzed for findings (e.g., scripts, requests, links).
                    }
                }
            }
        }));

        // Process DNS information
        tasks.push(tokio::spawn({
            let findings = Arc::clone(&findings);
            let target = target.to_string();
            let dns_information: Vec<serde_json::Value> = dns_information.to_vec(); // Clone for the task
            async move {
                for dns_result in dns_information {
                    // Check SPF records
                    if let Some(records) = dns_result.get("records").and_then(|r| r.as_object()) {
                        if let Some(txt_records) = records.get("TXT").and_then(|t| t.as_array()) {
                            let has_spf = txt_records.iter().any(|r| {
                                r.as_str().map_or(false, |s| s.contains("v=spf1"))
                            });

                            if !has_spf {
                                let mut findings_lock = findings.lock().await;
                                findings_lock.push(Finding {
                                    id: format!("FINDING-DNS-MISSING-SPF-{}", findings_lock.len()), // Unique ID
                                    target_id: target.clone(),
                                    subdomain_id: dns_result.get("domain").and_then(|d| d.as_str()).filter(|d| d != &target).map(|d| d.to_string()),
                                    finding_type: "Missing SPF Record".to_string(),
                                    severity: "Low".to_string(),
                                    url: None, // No specific URL
                                    description: format!(
                                        "Domain {} is missing an SPF record, which may lead to email spoofing. SPF records help prevent unauthorized senders from using your domain to send emails, reducing spam and phishing attempts.",
                                        dns_result.get("domain").and_then(|d| d.as_str()).unwrap_or(&target)
                                    ),
                                    discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                    dork_used: None,
                                    screenshot_path: None,
                                    has_sensitive_data: false,
                                });
                            }

                            // Check DMARC records
                            let has_dmarc = txt_records.iter().any(|r| {
                                r.as_str().map_or(false, |s| s.contains("v=DMARC1"))
                            });

                            if !has_dmarc {
                                let mut findings_lock = findings.lock().await;
                                findings_lock.push(Finding {
                                    id: format!("FINDING-DNS-MISSING-DMARC-{}", findings_lock.len()), // Unique ID
                                    target_id: target.clone(),
                                    subdomain_id: dns_result.get("domain").and_then(|d| d.as_str()).filter(|d| d != &target).map(|d| d.to_string()),
                                    finding_type: "Missing DMARC Record".to_string(),
                                    severity: "Low".to_string(),
                                    url: None, // No specific URL
                                    description: format!(
                                        "Domain {} is missing a DMARC record, which helps protect against email spoofing and phishing. DMARC works with SPF and DKIM to provide stronger email authentication.",
                                        dns_result.get("domain").and_then(|d| d.as_str()).unwrap_or(&target)
                                    ),
                                    discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                    dork_used: None,
                                    screenshot_path: None,
                                    has_sensitive_data: false,
                                });
                            }
                             // Note: DKIM is typically checked via DNS TXT records as well.
                        }

                        // Check for DNSSEC
                        let has_dnssec = records.get("DNSKEY").is_some() || records.get("DS").is_some();

                        if !has_dnssec {
                            let mut findings_lock = findings.lock().await;
                            findings_lock.push(Finding {
                                id: format!("FINDING-DNS-DNSSEC-NOT-ENABLED-{}", findings_lock.len()), // Unique ID
                                target_id: target.clone(),
                                subdomain_id: dns_result.get("domain").and_then(|d| d.as_str()).filter(|d| d != &target).map(|d| d.to_string()),
                                finding_type: "DNSSEC Not Enabled".to_string(),
                                severity: "Low".to_string(),
                                url: None, // No specific URL
                                description: format!(
                                    "Domain {} does not have DNSSEC enabled, which makes it vulnerable to DNS spoofing and cache poisoning attacks. DNSSEC adds cryptographic signatures to DNS records to ensure their authenticity.",
                                    dns_result.get("domain").and_then(|d| d.as_str()).unwrap_or(&target)
                                ),
                                discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                                dork_used: None,
                                screenshot_path: None,
                                has_sensitive_data: false,
                            });
                        }
                    }
                     // Note: More DNS record types (e.g., MX, A, AAAA, CNAME) could be analyzed for info disclosure.
                }
            }
        }));

        // Process cloud storage findings
        tasks.push(tokio::spawn({
            let findings = Arc::clone(&findings);
            let target = target.to_string();
            let cloud_storage: Vec<serde_json::Value> = cloud_storage.to_vec(); // Clone for the task
            async move {
                for storage_result in cloud_storage {
                    // All cloud storage findings are potentially sensitive
                    let mut findings_lock = findings.lock().await;
                    findings_lock.push(Finding {
                        id: format!("FINDING-CLOUD-STORAGE-EXPOSURE-{}", findings_lock.len()), // Unique ID
                        target_id: target.clone(),
                        subdomain_id: storage_result.get("domain").and_then(|d| d.as_str()).filter(|d| d != &target).map(|d| d.to_string()), // Attempt to extract domain from result
                        finding_type: "Cloud Storage Exposure".to_string(),
                        severity: "Medium".to_string(),
                        url: storage_result.get("url").and_then(|u| u.as_str()).map(|s| s.to_string()),
                        description: format!(
                            "Exposed cloud storage found: {} ({}). Publicly accessible cloud storage can lead to data leaks if it contains sensitive information. Consider restricting access controls or making the bucket private.\n\nRecommendation: Review access controls for the cloud storage resource and restrict public access.",
                            storage_result.get("title").and_then(|t| t.as_str()).unwrap_or("Unknown"),
                            storage_result.get("storage_type").and_then(|t| t.as_str()).unwrap_or("Unknown")
                        ),
                        discovery_timestamp: SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().as_secs(),
                        dork_used: storage_result.get("dork_used").and_then(|d| d.as_str()).map(|s| s.to_string()), // If dork was used
                        screenshot_path: None, // Cloud storage results might not have screenshots
                        has_sensitive_data: true, // Mark as potentially sensitive
                    });
                }
            }
        }));


        // Wait for all tasks to complete
        let results = join_all(tasks).await;
         for res in results {
             if let Err(e) = res {
                 eprintln!("Error in analysis task: {}", e); // Log errors from tasks
             }
         }


        // Extract and sort findings by severity
        let mut result = Arc::try_unwrap(findings)
            .unwrap_or_else(|_| panic!("Failed to unwrap Arc"))
            .into_inner();

        // Sort by severity (Critical -> High -> Medium -> Low -> Info)
        result.sort_by(|a, b| {
            let a_severity = convert_severity_to_numeric(&a.severity);
            let b_severity = convert_severity_to_numeric(&b.severity);
            b_severity.cmp(&a_severity)
        });

        // Deduplicate findings by combining similar ones (based on finding type and URL)
        let result = self.deduplicate_findings(result);

        println!("Analysis complete. Found {} unique findings", result.len());

        Ok(result)
    }

    /// Deduplicate and merge similar findings
    fn deduplicate_findings(&self, findings: Vec<Finding>) -> Vec<Finding> {
        let mut unique_findings = Vec::new();
        let mut seen_findings_key = HashMap::new(); // Use a key (type + URL) to track seen findings

        for finding in findings {
            // Create a key for deduplication
            let key = format!("{}:{}", finding.finding_type, finding.url.as_deref().unwrap_or(""));

            if let Some(&existing_idx) = seen_findings_key.get(&key) {
                // Found a similar finding, merge information
                let existing = &mut unique_findings[existing_idx];

                // Combine descriptions, add dork used if new
                let combined_desc = if existing.description.contains(&finding.description) {
                    existing.description.clone() // Avoid duplicating description if already present
                } else {
                    format!("{}\n\nAdditional information: {}", existing.description, finding.description)
                };
                existing.description = combined_desc;

                // Take the higher severity
                if convert_severity_to_numeric(&finding.severity) >
                   convert_severity_to_numeric(&existing.severity) {
                    existing.severity = finding.severity;
                }

                // Add dork if present and not already in the description (simple check)
                if let Some(dork) = &finding.dork_used {
                     if !existing.description.contains(dork) {
                         existing.description = format!("{}\n\nDiscovered with dork: {}", existing.description, dork);
                     }
                }

                // Update sensitive data flag if either is true
                existing.has_sensitive_data = existing.has_sensitive_data || finding.has_sensitive_data;

                 // Update timestamp to the latest discovery time
                 existing.discovery_timestamp = existing.discovery_timestamp.max(finding.discovery_timestamp);


            } else {
                // New unique finding
                seen_findings_key.insert(key, unique_findings.len());
                unique_findings.push(finding);
            }
        }

        unique_findings
    }
}

// Helper function to convert severity string to numeric value for sorting
fn convert_severity_to_numeric(severity: &str) -> u8 {
    match severity.to_lowercase().as_str() {
        "critical" => 4,
        "high" => 3,
        "medium" => 2,
        "low" => 1,
        "info" | "informational" => 0,
        _ => 0, // Default for unknown severity
    }
}

/// Helper function to extract domain from URL
fn extract_domain(url: &str) -> Option<&str> {
    // Use the url crate for proper URL parsing
    Url::parse(url).ok().and_then(|u| u.host_str())
}

// Add tokio sleep for async delay (already in scope from tokio::time::sleep)

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::test; // Use tokio test for async tests
    use serde_json::json; // Added for easily creating JSON values in tests

    #[test]
    fn test_analyze_content() {
        let matcher = VulnerabilityMatcher::new();

        // Test SQL injection detection
        let content = "This page has an error: SQL syntax error near 'WHERE'";
        let url = "https://example.com/page";

        let matches = matcher.analyze_content(url, content);
        assert!(!matches.is_empty());
        assert_eq!(matches[0].pattern_id, "SQLI-01");

        // Test false positive detection
        let documentation = "Example of SQL syntax error in documentation: SQL syntax error near 'WHERE'";
        let matches = matcher.analyze_content(url, documentation);
        assert!(matches.is_empty());
    }

    #[test]
    fn test_extract_context() {
        let matcher = VulnerabilityMatcher::new();

        let content = "This is a test with a vulnerability in the middle and some more text after it.";
        let match_start = content.find("vulnerability").unwrap();
        let match_end = match_start + "vulnerability".len();

        let context = matcher.extract_context(content, match_start, match_end);
        assert!(context.contains("[MATCH: vulnerability]")); // Check for highlighting
        // Since context extraction is heuristic, check if it's within a reasonable range
        assert!(context.len() > ("vulnerability".len() + 2 * (matcher.context_config.before_chars + matcher.context_config.after_chars)) / 2); // Check it's not too short


        let content_with_newlines = "Line one.\nThis is a test.\nLine three with vulnerability here.\nLine four.";
        let match_start_nl = content_with_newlines.find("vulnerability").unwrap();
        let match_end_nl = match_start_nl + "vulnerability".len();

        let context_nl = matcher.extract_context(content_with_newlines, match_start_nl, match_end_nl);
         assert!(context_nl.contains("Line three with [MATCH: vulnerability] here."));

    }

    #[test]
    fn test_is_false_positive() {
        let matcher = VulnerabilityMatcher::new();

        // Test pattern-specific check
        let pattern_checks = vec!["example".to_string()];
        let context = "This is an example of SQL injection";
        let pattern = &matcher.patterns[0]; // SQL injection pattern

        assert!(matcher.is_false_positive(&pattern_checks, context, pattern, "http://example.com")); // Use a valid URL

        // Test non-false positive
        let context = "This is a real SQL injection vulnerability";
        assert!(!matcher.is_false_positive(&pattern_checks, context, pattern, "http://example.com/real_vuln")); // Use a valid URL

         // Test API key placeholder false positive
         let context_api = "const apiKey = 'YOUR_API_KEY';";
         let pattern_api = matcher.patterns.iter().find(|p| p.id == "EXPOSURE-01").unwrap(); // API key pattern
         assert!(matcher.is_false_positive(&pattern_api.false_positive_checks, context_api, pattern_api, "http://example.com/script.js"));
    }

    #[tokio::test]
    async fn test_process_dork_results() {
        let target = "example.com";
        let dork_results = vec![
            DorkResult {
                url: "https://example.com/admin".to_string(),
                title: "Admin Panel".to_string(),
                snippet: "Login to the admin panel".to_string(),
                content_type: None,
                found_dork: "site:example.com inurl:admin".to_string(),
            },
             DorkResult {
                url: "https://sub.example.com/sensitive-data".to_string(),
                title: "Sensitive File".to_string(),
                snippet: "Contains user passwords: password123".to_string(),
                content_type: None,
                found_dork: "site:example.com intext:password".to_string(),
            }
        ];

        let matcher = VulnerabilityMatcher::new();

        // Simulate calling the analysis process with dork results
        let findings = matcher.analyze_findings(
            target,
            &dork_results,
            &[], // Empty other results for this test
            &[],
            &[],
            &[],
            &[],
        ).await.unwrap(); // Use .unwrap() in test for simplicity


        assert!(!findings.is_empty());
        // Check for the exposed admin URL finding
        assert!(findings.iter().any(|f| f.finding_type == "Exposed Admin Interface URL" && f.url == Some("https://example.com/admin".to_string())));
         // Check for the sensitive data finding (from snippet analysis)
         assert!(findings.iter().any(|f| f.finding_type == "API Key Exposure" || f.description.contains("passwords"))); // Assuming the password match falls under a pattern

    }


    #[tokio::test]
    async fn test_process_js_analysis() {
        let target = "example.com";
        let js_analysis = vec![
            json!({
                "url": "https://example.com/app.js",
                "api_keys": [
                    {
                        "type": "api_key",
                        "value": "abcdef1234567890"
                    }
                ],
                "has_credentials": true,
                 "endpoints": [
                    {"url": "/api/v1/users", "method": "GET"},
                    {"url": "https://external.api.com/data", "method": "POST", "parameters": ["id", "token"]}
                 ]
            })
        ];

        let matcher = VulnerabilityMatcher::new();

        // Simulate calling the analysis process with js analysis results
        let findings = matcher.analyze_findings(
            target,
            &[], // Empty other results
            &[],
            &[],
            &[],
            &js_analysis,
            &[],
        ).await.unwrap();


        assert!(!findings.is_empty());
        assert!(findings.iter().any(|f| f.finding_type == "API Key Exposure"));
        assert!(findings.iter().any(|f| f.finding_type == "Hard-coded Credentials"));
         // Endpoints are collected separately in main.rs, not added as Findings here.
    }


    #[test]
    fn test_severity_sorting() {
        let findings = vec![
            Finding {
                id: "1".to_string(), target_id: "example.com".to_string(), subdomain_id: None,
                finding_type: "Low Priority".to_string(), severity: "Low".to_string(), url: None,
                description: "Low severity finding".to_string(), discovery_timestamp: 0, dork_used: None,
                screenshot_path: None, has_sensitive_data: false,
            },
            Finding {
                id: "2".to_string(), target_id: "example.com".to_string(), subdomain_id: None,
                finding_type: "Critical Priority".to_string(), severity: "Critical".to_string(), url: None,
                description: "Critical severity finding".to_string(), discovery_timestamp: 0, dork_used: None,
                screenshot_path: None, has_sensitive_data: false,
            },
             Finding {
                id: "3".to_string(), target_id: "example.com".to_string(), subdomain_id: None,
                finding_type: "Medium Priority".to_string(), severity: "Medium".to_string(), url: None,
                description: "Medium severity finding".to_string(), discovery_timestamp: 0, dork_used: None,
                screenshot_path: None, has_sensitive_data: false,
            }
        ];

        // Sort by severity
        let mut sorted = findings.clone();
        sorted.sort_by(|a, b| {
            let a_severity = convert_severity_to_numeric(&a.severity);
            let b_severity = convert_severity_to_numeric(&b.severity);
            b_severity.cmp(&a_severity)
        });

        // Verify sort order
        assert_eq!(sorted[0].severity, "Critical");
        assert_eq!(sorted[1].severity, "Medium");
        assert_eq!(sorted[2].severity, "Low");
    }

    #[test]
    fn test_extract_domain() {
        assert_eq!(extract_domain("https://example.com/path"), Some("example.com"));
        assert_eq!(extract_domain("http://sub.example.com:8080/page"), Some("sub.example.com"));
        assert_eq!(extract_domain("example.com"), None);
        assert_eq!(extract_domain("ftp://ftp.example.com"), Some("ftp.example.com"));
         assert_eq!(extract_domain("invalid-url"), None);
    }

    #[test]
    fn test_deduplicate_findings() {
        let matcher = VulnerabilityMatcher::new();

        let findings = vec![
            Finding {
                id: "1".to_string(), target_id: "example.com".to_string(), subdomain_id: None,
                finding_type: "Error Disclosure".to_string(), severity: "Medium".to_string(),
                url: Some("http://example.com/page1".to_string()), description: "Error message 1".to_string(),
                discovery_timestamp: 100, dork_used: Some("dork1".to_string()), screenshot_path: None, has_sensitive_data: false,
            },
             Finding {
                id: "2".to_string(), target_id: "example.com".to_string(), subdomain_id: None,
                finding_type: "Error Disclosure".to_string(), severity: "Low".to_string(),
                url: Some("http://example.com/page1".to_string()), description: "Error message 2".to_string(),
                discovery_timestamp: 200, dork_used: Some("dork2".to_string()), screenshot_path: None, has_sensitive_data: false,
            },
             Finding {
                id: "3".to_string(), target_id: "example.com".to_string(), subdomain_id: None,
                finding_type: "API Key Exposure".to_string(), severity: "High".to_string(),
                url: Some("http://example.com/script.js".to_string()), description: "API key found".to_string(),
                discovery_timestamp: 150, dork_used: None, screenshot_path: None, has_sensitive_data: true,
            }
        ];

        let deduplicated = matcher.deduplicate_findings(findings);

        assert_eq!(deduplicated.len(), 2); // Should have 2 unique findings

        // Check the merged finding
        let error_finding = deduplicated.iter().find(|f| f.finding_type == "Error Disclosure").unwrap();
        assert_eq!(error_finding.severity, "Medium"); // Should take higher severity
        assert!(error_finding.description.contains("Error message 1"));
        assert!(error_finding.description.contains("Error message 2"));
        assert!(error_finding.description.contains("dork1")); // Should include dork
        assert!(error_finding.description.contains("dork2")); // Should include dork
        assert_eq!(error_finding.discovery_timestamp, 200); // Should take latest timestamp


        // Check the other finding
        let api_finding = deduplicated.iter().find(|f| f.finding_type == "API Key Exposure").unwrap();
        assert_eq!(api_finding.severity, "High");
        assert_eq!(api_finding.url, Some("http://example.com/script.js".to_string()));
        assert!(api_finding.has_sensitive_data);

    }
}